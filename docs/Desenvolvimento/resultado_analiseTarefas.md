|    **Data**    | **Data Prevista de Revisão** | **Versão** |        **Descrição**        |                 **Autor**                 |                **Revisor**                 |
|:--------------:|:---------------------------:|:----------:|:---------------------------:|:-----------------------------------------:|:------------------------------------------:|
|  05/01/2025    |        05/01/2025          |    1.0     |     Criação do Documento     | [Paola Nascimento](https://github.com/paolaalim) |  [Karolina Vieira](https://github.com/Karolina91) |

# **Resultado do Relato da Análise de Tarefas**

## Introdução

Esse artefato tem o objetivo de documentar o relato dos resultados obtidos pela avaliação da Análise de Tarefas. Com isso, serão abordados os tópicos referidos no [Planejamento do Relato dos Resultados da Análise de Tarefas](./planejamentoRelatoAnaliseTarefas.md)


### Objetivo e âmbito da avaliação

A avaliação teve como propósito examinar se os artefatos gerados na análise de tarefas estão alinhados com os critérios estabelecidos para esse tipo de artefato, se os requisitos necessários estão sendo cumpridos e se há alguma proposta de design alternativa para a análise.

### Método de avaliação

Conforme sugerido pelo [Planejamento da avaliação da análise de tarefas](./analiseDeTarefas.md) avaliação escolhido foi o de investigação, onde há observação e entrevistas.

A Tabela 1 exibe as datas da realização da avaliação.

<center>

<font size="2"><p style="text-align: center">Tabela 1: Cronograma executado</p></font>

| Entrevistador | Entrevistado  | Horário de Início | Horário de Fim | Data  | Local/Plataforma |
| :-----------: | :-----------: | :---------------: | :------------: | :---: | :--------------: |
|   Karolina Vieira|  Fernanda  | 15:30  |  16:00  |   02/01/2025 | Residencia |
|   Paola Nascimento| Vanda  | 16:00 |  16:30  | 04/01/2025  | Residencia |

## Registros das avaliações

## Entrevista - Agendamento para uma consulta com um advogado

<font size="2"><p style="text-align: center">Fonte: 
[Karolina Vieira](https://github.com/Karolina91)

</center>

No Video 1 e Tabela 2 é possível verificar os registros feitos durante a avaliação.
### Video 1: Gravação da avaliação

[Assista ao vídeo no YouTube](https://youtu.be/py4Ez_CUAWQ)

#### Fonte:
[Karolina Vieira ](https://github.com/Karolina91)


<font size="2"><p style="text-align: center">Tabela 2: Sumario de perguntas</p></font>

| Pergunta | Resposta |
|--------------------------------------------------------------------------------------------------------------|:------:|
| Os objetivos da tarefa estão claramente definidos no modelo? | Sim  |
| As operações são realistas e compatíveis com a tarefa analisada? | Sim   |
| As análises são de fácil entendimento?| Sim  |
| As operações retratadas estão alinhadas com o título? | Sim  |
| O modelo aborda adequadamente os principais aspectos da realização da tarefa? | Sim |
| As ações descritas seguem uma sequência lógica e fluida? | Sim  |
| A tarefa cumpre seu propósito? | Sim  |
| O modelo apresenta elementos visuais identificáveis, como personagens, objetos e cenários? |  Não |
| O nível de decomposição da tarefa é adequado para a análise proposta? | Sim  |
| O modelo facilita a compreensão dos passos necessários para a realização da tarefa? | Sim  |
| O modelo identifica corretamente decisões e alternativas dentro da tarefa? |  Não |
| O modelo apresenta alguma falha grave na estruturação da tarefa? |  Não |
| Tem alguma sugestão de melhoria do procesos? | Sim |

<font size="2"><p style="text-align: center">Fonte:
[ Karolina Vieira](https://github.com/Karolina91)

## Sumário de Avaliadores e Participantes
A seleção do entrevistado foi baseada em critérios que atendem ao perfil desejado. O participante escolhido está na faixa etária compatível com o perfil do público-alvo, o que garante a representatividade necessária para a avaliação. Além disso, ele possui uma boa relação com a tecnologia e demonstra familiaridade com o sistema avaliado. Esses fatores são fundamentais para assegurar que os insights obtidos reflitam a experiência real de uso, contribuindo para a eficácia e relevância dos resultados.

## Sumário dos Dados Coletados
Os dados obtidos mostram que a análise de tarefas reflete a realidade dos usuários, com baixa frequência de erros, tempo médio eficiente para conclusão das tarefas e alto nível de satisfação. O sistema se mostrou funcional, intuitivo e alinhado às necessidades do público-alvo.

### Análise dos Dados Coletados
O HTA está bem estruturado, alinhado ao título e reflete a realidade com ações lógicas e fluídas. O principal problema identificado é a ausência de elementos visuais, o que pode dificultar a compreensão e a interpretação. Recomenda-se incluir visuais para melhorar a clareza e usabilidade.

### Sugestões de Melhoria
Incluir elementos visuais, como personagens, objetos e cenários, para complementar as descrições textuais e facilitar a compreensão das tarefas. Isso tornará o HTA mais acessível, intuitivo e visualmente claro para os usuários.

## Entrevista - Inscrever-se no Programa de Estágio da DPDF

<font size="2"><p style="text-align: center">Fonte: 
[Paola Nascimento](https://github.com/paolaalim)

</center>

## Registro da avaliação

No Video 2 e Tabela 3 é possível verificar os registros feitos durante a avaliação.
### Video 2: Gravação da avaliação

[Assista ao vídeo no YouTube](https://youtu.be/0PMKlVTV8w8)

#### Fonte:
[Paola Nascimento ](https://github.com/paolaalim)


<font size="2"><p style="text-align: center">Tabela 3: Sumario de perguntas</p></font>

| Pergunta | Resposta |
|--------------------------------------------------------------------------------------------------------------|:------:|
| Os objetivos da tarefa estão claramente definidos no modelo? | Sim  |
| As operações são realistas e compatíveis com a tarefa analisada? | Sim   |
| As análises são de fácil entendimento?| Sim  |
| As operações retratadas estão alinhadas com o título? | Sim  |
| O modelo aborda adequadamente os principais aspectos da realização da tarefa? | Sim |
| As ações descritas seguem uma sequência lógica e fluida? | Sim  |
| A tarefa cumpre seu propósito? | Sim  |
| O modelo apresenta elementos visuais identificáveis, como personagens, objetos e cenários? |  Não |
| O nível de decomposição da tarefa é adequado para a análise proposta? | Sim  |
| O modelo facilita a compreensão dos passos necessários para a realização da tarefa? | Sim  |
| O modelo identifica corretamente decisões e alternativas dentro da tarefa? |  Não |
| O modelo apresenta alguma falha grave na estruturação da tarefa? |  Não |
| Tem alguma sugestão de melhoria do procesos? | Sim |

<font size="2"><p style="text-align: center">Fonte:
[Paola Nascimento](https://github.com/paolaalim)


## Sumário de Avaliadores e Participantes
Os testes de usabilidade foram planejados com a participação de três usuários, conforme recomendado por Krug. No entanto, devido a circunstâncias imprevistas, apenas uma participante pôde ser envolvida. Krug destaca que, embora o ideal seja testar com três ou quatro usuários, realizar o teste com um é mais vantajoso do que não realizá-lo.
A seleção da entrevistada foi baseada em critérios que atendem ao perfil desejado. A participante escolhido está na faixa etária compatível com o perfil do público-alvo que utiliza o sitema, por mais que não realizem a ação específica. Além disso, ela possui uma boa relação com a tecnologia e demonstra familiaridade com a situação apresentada pelo sistema avaliado. 

## Sumário dos Dados Coletados
Os dados obtidos mostram que a análise de tarefas reflete a realidade dos usuários, com baixa frequência de erros, tempo médio eficiente para conclusão das tarefas e alto nível de satisfação. O sistema se mostrou funcional, intuitivo e alinhado às necessidades do público-alvo.

### Análise dos Dados Coletados
O HTA e o GOMS estão bem estruturados, com ações lógicas e fluídas, títulos e tarefas condizentes com as situações retratadas. 

### Sugestões de Melhoria
Incluir elementos visuais e as alternativas (se aplicável) dentro de cada tarefa para facilitar a compreensão delas. Isso tornará o HTA mais acessível e as possibilidades mais claras.


## Referências Bibliográficas
BARBOSA, Simone; DINIZ, Bruno. *Interação Humano-Computador*. Editora Elsevier, Rio de Janeiro, 2010.
